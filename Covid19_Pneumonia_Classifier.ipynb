{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid19_Pneumonia_Classifier",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGMUp_FRQKRd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f3926f28-02fd-443c-aa94-47941d5ff2d7"
      },
      "source": [
        "!rm -r /content/dats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/dats': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x7RWJ0TPBZ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "79456623-9aad-44f5-d36a-8ef3a1fecc69"
      },
      "source": [
        "!git clone https://github.com/ieee8023/covid-chestxray-dataset.git\n",
        "!pip install torchxrayvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'covid-chestxray-dataset'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 3651 (delta 13), reused 21 (delta 8), pack-reused 3615\u001b[K\n",
            "Receiving objects: 100% (3651/3651), 632.29 MiB | 16.59 MiB/s, done.\n",
            "Resolving deltas: 100% (1455/1455), done.\n",
            "Checking out files: 100% (1164/1164), done.\n",
            "Collecting torchxrayvision\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/99/bae999ca5b1208af9ad1609436112fb4c38492fca6c393a16ef2ac8ff07c/torchxrayvision-0.0.17-py3-none-any.whl (40.4MB)\n",
            "\u001b[K     |████████████████████████████████| 40.4MB 74kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1 in /usr/local/lib/python3.6/dist-packages (from torchxrayvision) (1.6.0+cu101)\n",
            "Requirement already satisfied: tqdm>=4 in /usr/local/lib/python3.6/dist-packages (from torchxrayvision) (4.41.1)\n",
            "Requirement already satisfied: scikit-image>=0.16 in /usr/local/lib/python3.6/dist-packages (from torchxrayvision) (0.16.2)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from torchxrayvision) (0.7.0+cu101)\n",
            "Requirement already satisfied: requests>=1 in /usr/local/lib/python3.6/dist-packages (from torchxrayvision) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1 in /usr/local/lib/python3.6/dist-packages (from torchxrayvision) (1.18.5)\n",
            "Collecting pydicom>=1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/56/342e1f8ce5afe63bf65c23d0b2c1cd5a05600caad1c211c39725d3a4cc56/pydicom-2.0.0-py3-none-any.whl (35.4MB)\n",
            "\u001b[K     |████████████████████████████████| 35.5MB 90kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1 in /usr/local/lib/python3.6/dist-packages (from torchxrayvision) (1.0.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1->torchxrayvision) (0.16.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16->torchxrayvision) (2.5)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16->torchxrayvision) (7.0.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16->torchxrayvision) (2.4.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16->torchxrayvision) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16->torchxrayvision) (1.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.16->torchxrayvision) (3.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=1->torchxrayvision) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=1->torchxrayvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=1->torchxrayvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=1->torchxrayvision) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=1->torchxrayvision) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1->torchxrayvision) (2018.9)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.16->torchxrayvision) (4.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16->torchxrayvision) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16->torchxrayvision) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.16->torchxrayvision) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=1->torchxrayvision) (1.15.0)\n",
            "Installing collected packages: pydicom, torchxrayvision\n",
            "Successfully installed pydicom-2.0.0 torchxrayvision-0.0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSanW8M_jrI9",
        "cellView": "both",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "2cdf5f52-87e0-4ba4-bd08-819ba870d086"
      },
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "\n",
        "files.upload()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b0bca7b0-a169-4dc2-b13e-a04a1d5e5ca4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b0bca7b0-a169-4dc2-b13e-a04a1d5e5ca4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"randheerrameshk\",\"key\":\"834af696027448aefdad59ac88e7f588\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDIjn_eQukM1"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC9GZnIEjbdE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "202fd03d-b945-41f2-ffb3-5ebbaab6ec6f"
      },
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading chest-xray-pneumonia.zip to /content\n",
            "100% 2.29G/2.29G [00:55<00:00, 78.8MB/s]\n",
            "100% 2.29G/2.29G [00:55<00:00, 44.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qELbjqO3Pkta"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import shutil\n",
        "import math\n",
        "from zipfile import ZipFile\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.optim import lr_scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMVbfEWmWkjU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "598bff03-afa1-4fe8-9dd0-52b61dc99b32"
      },
      "source": [
        "shutil.copytree(\"/content/drive/My Drive/Dataset\", \"/content/data\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/data'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9XagGbXld6y"
      },
      "source": [
        "with ZipFile(\"/content/chest-xray-pneumonia.zip\", 'r') as z :\n",
        "  z.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imrAOTl0v6Wd"
      },
      "source": [
        "def create_dir_structure() :\n",
        "  paths = [ \"/content/Dataset/train/covid19\",\n",
        "            \"/content/Dataset/train/normal\",\n",
        "            \"/content/Dataset/train/pneumonia\",\n",
        "            \"/content/Dataset/val/covid19\",\n",
        "            \"/content/Dataset/val/normal\",\n",
        "            \"/content/Dataset/val/pneumonia\",\n",
        "            \"/content/covid19\",\n",
        "            \"/content/normal\",\n",
        "            \"/content/pneumonia\" ]\n",
        "  for path in paths :\n",
        "    os.makedirs(path)\n",
        "create_dir_structure()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN-hEwfJuVwn"
      },
      "source": [
        "def covid19ImageFolder() :\n",
        "  df = pd.read_csv(\"/content/covid-chestxray-dataset/metadata.csv\")\n",
        "  dataFrame = df[['finding', 'folder', 'filename']]\n",
        "  i=0\n",
        "  for finding, folder, filename in dataFrame.values :\n",
        "    if(finding==\"COVID-19\") :\n",
        "      try :\n",
        "        img = Image.open(\"/content/covid-chestxray-dataset/\"+folder+\"/\"+filename)\n",
        "        i+=1\n",
        "        shutil.copy(\"/content/covid-chestxray-dataset/\"+folder+\"/\"+filename, \"/content/covid19\")\n",
        "      except :\n",
        "        print(\"cant open \"+filename)\n",
        "\n",
        "covid19ImageFolder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esv0a1aYS0N9"
      },
      "source": [
        "def normalImageFolder() :\n",
        "  i=0\n",
        "  for filename in os.listdir(\"/content/chest_xray/train/NORMAL\") :\n",
        "    if i<522:\n",
        "      try :\n",
        "        img = Image.open(\"/content/chest_xray/train/NORMAL/\"+filename)\n",
        "        i+=1\n",
        "        shutil.copy(\"/content/chest_xray/train/NORMAL/\"+filename, \"/content/normal\")\n",
        "      except :\n",
        "        print(\"cant open \")\n",
        "\n",
        "normalImageFolder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuOvFe2xi3FV"
      },
      "source": [
        "def pneumoniaImageFolder() :   \n",
        "  i=0\n",
        "  for filename in os.listdir(\"/content/chest_xray/train/PNEUMONIA\") :\n",
        "    if i<522:\n",
        "      try :\n",
        "        img = Image.open(\"/content/chest_xray/train/PNEUMONIA/\"+filename)\n",
        "        i+=1\n",
        "        shutil.copy(\"/content/chest_xray/train/PNEUMONIA/\"+filename, \"/content/pneumonia\")\n",
        "      except :\n",
        "        print(\"cant open \")\n",
        "\n",
        "pneumoniaImageFolder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixkOdI0Pynac"
      },
      "source": [
        "def copyFiles(folderList) :\n",
        "  for folder in folderList :\n",
        "    i = 0\n",
        "    for filename in os.listdir(\"/content/\"+folder) :\n",
        "      if(i<432) :\n",
        "        shutil.copy(\"/content/\"+folder+\"/\"+filename, \"/content/Dataset/train/\"+folder+\"/\")\n",
        "      else :\n",
        "        shutil.copy(\"/content/\"+folder+\"/\"+filename, \"/content/Dataset/val/\"+folder+\"/\")\n",
        "      i+=1\n",
        "folderList = [ 'covid19', 'normal', 'pneumonia']\n",
        "copyFiles(folderList)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zov8z52UVW7"
      },
      "source": [
        "root = \"/content/data\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0nBtoTtZ2_C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2f94cde6-145e-4116-8736-2d3416fe203f"
      },
      "source": [
        "os.listdir(root)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'val']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj3MjIp_Z7GE"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsDbPacVbdeN"
      },
      "source": [
        "image_datasets = {x: ImageFolder(os.path.join(root, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkthj5JecGsi"
      },
      "source": [
        "class_names = image_datasets['train'].classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WESus41RgJCv"
      },
      "source": [
        "class FCC(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.5):\n",
        "        super().__init__()\n",
        "        layer_sizes = [input_size] + hidden_layers + [output_size]\n",
        "        self.classifier = nn.Sequential()\n",
        "        for index, (inp, out) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
        "            self.classifier.add_module('fc' + str(index), nn.Linear(inp, out))\n",
        "            if index < (len(layer_sizes) - 2):  \n",
        "                self.classifier.add_module('relu' + str(index + 1), nn.ReLU())\n",
        "                self.classifier.add_module('dropout' + str(index + 1), nn.Dropout(drop_p))\n",
        "        self.classifier.add_module('output', nn.LogSoftmax(dim=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDEUD_6zglqA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "272d9dc4-61ba-4de2-8406-13af91a9c9c9"
      },
      "source": [
        "fcc = FCC(input_size=20588, output_size=102, hidden_layers=[2048, 512], drop_p=0.5)\n",
        "print(fcc.classifier)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (fc0): Linear(in_features=20588, out_features=2048, bias=True)\n",
            "  (relu1): ReLU()\n",
            "  (dropout1): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
            "  (relu2): ReLU()\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc2): Linear(in_features=512, out_features=102, bias=True)\n",
            "  (output): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruz2wc-ig1-u"
      },
      "source": [
        "def create_model(arch='vgg16', output_size=102, class_to_idx=None, hidden_layers=[4096, 4096], drop_p=0.5):\n",
        "    input_size = 25088\n",
        "    \n",
        "    model = torch.hub.load('pytorch/vision:v0.6.0', 'vgg16', pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    fc = FCC(input_size=input_size, output_size=output_size,\n",
        "                      hidden_layers=hidden_layers, drop_p=drop_p).classifier\n",
        "    \n",
        "    model.classifier = fc\n",
        "    model.arch = arch\n",
        "    model.class_to_idx = class_to_idx\n",
        "    model.output_size = output_size\n",
        "    model.hidden_layers = hidden_layers\n",
        "    model.drop_p = drop_p\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Bdb9KEg2w2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "outputId": "7bea825d-3139-488c-862f-0db9bc949e84"
      },
      "source": [
        "model = create_model(arch='resnet18')\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (fc0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (relu1): ReLU()\n",
            "    (dropout1): Dropout(p=0.5, inplace=False)\n",
            "    (fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (relu2): ReLU()\n",
            "    (dropout2): Dropout(p=0.5, inplace=False)\n",
            "    (fc2): Linear(in_features=4096, out_features=102, bias=True)\n",
            "    (output): LogSoftmax(dim=1)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBC9t_oVg7tp"
      },
      "source": [
        "def create_optimizer(model, lr=0.001):\n",
        "    params = model.classifier.parameters()\n",
        "    optimizer = optim.Adam(params, lr=lr)\n",
        "    return  optimizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8Bib9h4hEGh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "1bd64d02-656c-4146-8252-8bc417dcc78e"
      },
      "source": [
        "optimizer = create_optimizer(model)\n",
        "print(optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRBL95B1hSEi"
      },
      "source": [
        "def select_device(gpu):\n",
        "    if not torch.cuda.is_available():\n",
        "        print('GPU is not available')\n",
        "        return torch.device('cpu')\n",
        "    device = torch.device('cuda:0') if gpu else torch.device('cpu')  \n",
        "    return device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjCpUpfQhbsj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1bf84fc1-6e21-493c-f507-9c5a57d7ef3b"
      },
      "source": [
        "device = select_device(gpu=True)\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sVRz-zNhnt1"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, gpu=True,\n",
        "                start_epoch=1, epochs=25):\n",
        "    train_start = time.time()\n",
        "    model.train()\n",
        "    start_epoch=1\n",
        "    best_acc = 0 \n",
        "    best_epoch = 0\n",
        "    best_model_state_dict = copy.deepcopy(model.state_dict())\n",
        "    best_optimizer_state_dict = copy.deepcopy(optimizer.state_dict())\n",
        "    device = select_device(gpu)\n",
        "    model.to(device)\n",
        "    for epoch in range(start_epoch, start_epoch + epochs):\n",
        "        print(f'\\nEpoch {epoch}/{start_epoch + epochs - 1}:'\n",
        "              f'\\n---------------------') \n",
        "        for phase in ['train', 'val']:\n",
        "            phase_start = time.time()\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            running_loss = 0\n",
        "            running_corrects = 0\n",
        "            \n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                \n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "                \n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    pred = model(inputs)\n",
        "                    loss = criterion(pred, labels)\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                predictions = torch.exp(pred)\n",
        "                _, predictions = predictions.topk(1, dim=1)\n",
        "                equals = predictions == labels.view(*predictions.shape)\n",
        "                running_corrects += torch.sum(equals.type(torch.FloatTensor)).item()\n",
        "            \n",
        "            phase_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            phase_acc = running_corrects / len(dataloaders[phase].dataset)\n",
        "            \n",
        "            if phase == 'val' and phase_acc > best_acc:\n",
        "                best_epoch = epoch\n",
        "                best_acc = phase_acc\n",
        "                best_model_state_dict = copy.deepcopy(model.state_dict())\n",
        "                best_optimizer_state_dict = copy.deepcopy(optimizer.state_dict())\n",
        "                \n",
        "            phase_duration = time.time() - phase_start\n",
        "            print(f'{phase} Loss: {phase_loss:.4f}, Acc: {phase_acc:.4f}')\n",
        "            \n",
        "    model.load_state_dict(best_model_state_dict)\n",
        "    optimizer.load_state_dict(best_optimizer_state_dict)\n",
        "        \n",
        "    train_duration = time.time() - train_start\n",
        "    print(f'\\nTraining complete in {(train_duration):.0f}s '\n",
        "          f'Best Validation Acc: {best_acc:.4f}')\n",
        "    \n",
        "    return best_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq7ja0i3O4Eu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "27ee053c-09ac-4928-a9fc-567737570f0b"
      },
      "source": [
        "model = create_model(arch='vgg16', output_size=102, class_to_idx=image_datasets['train'].class_to_idx,\n",
        "                     hidden_layers=[2048, 512], drop_p=0.5)\n",
        "\n",
        "optimizer = create_optimizer(model=model, lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXQOmOzfh5wf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94e54870-484a-4f1d-f7f8-44da82b374a6"
      },
      "source": [
        "train_model(model=model, dataloaders=dataloaders, criterion=nn.CrossEntropyLoss(),\n",
        "                                  optimizer=optimizer, gpu=True, start_epoch=1, epochs=25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/25:\n",
            "---------------------\n",
            "train Loss: 1.2586, Acc: 0.6790\n",
            "val Loss: 0.2645, Acc: 0.9061\n",
            "\n",
            "Epoch 2/25:\n",
            "---------------------\n",
            "train Loss: 0.5362, Acc: 0.8032\n",
            "val Loss: 0.2498, Acc: 0.9386\n",
            "\n",
            "Epoch 3/25:\n",
            "---------------------\n",
            "train Loss: 0.5204, Acc: 0.8187\n",
            "val Loss: 0.2550, Acc: 0.9242\n",
            "\n",
            "Epoch 4/25:\n",
            "---------------------\n",
            "train Loss: 0.4960, Acc: 0.8264\n",
            "val Loss: 0.2321, Acc: 0.9314\n",
            "\n",
            "Epoch 5/25:\n",
            "---------------------\n",
            "train Loss: 0.5456, Acc: 0.8287\n",
            "val Loss: 0.2056, Acc: 0.9422\n",
            "\n",
            "Epoch 6/25:\n",
            "---------------------\n",
            "train Loss: 0.5130, Acc: 0.8202\n",
            "val Loss: 0.5394, Acc: 0.7942\n",
            "\n",
            "Epoch 7/25:\n",
            "---------------------\n",
            "train Loss: 0.5175, Acc: 0.8364\n",
            "val Loss: 0.2063, Acc: 0.9495\n",
            "\n",
            "Epoch 8/25:\n",
            "---------------------\n",
            "train Loss: 0.5565, Acc: 0.8164\n",
            "val Loss: 0.2709, Acc: 0.9061\n",
            "\n",
            "Epoch 9/25:\n",
            "---------------------\n",
            "train Loss: 0.4844, Acc: 0.8302\n",
            "val Loss: 0.2278, Acc: 0.9314\n",
            "\n",
            "Epoch 10/25:\n",
            "---------------------\n",
            "train Loss: 0.3607, Acc: 0.8673\n",
            "val Loss: 0.1847, Acc: 0.9531\n",
            "\n",
            "Epoch 11/25:\n",
            "---------------------\n",
            "train Loss: 0.4222, Acc: 0.8596\n",
            "val Loss: 0.2094, Acc: 0.9134\n",
            "\n",
            "Epoch 12/25:\n",
            "---------------------\n",
            "train Loss: 0.3909, Acc: 0.8642\n",
            "val Loss: 0.1779, Acc: 0.9422\n",
            "\n",
            "Epoch 13/25:\n",
            "---------------------\n",
            "train Loss: 0.4038, Acc: 0.8657\n",
            "val Loss: 0.1799, Acc: 0.9639\n",
            "\n",
            "Epoch 14/25:\n",
            "---------------------\n",
            "train Loss: 0.4967, Acc: 0.8364\n",
            "val Loss: 0.1760, Acc: 0.9567\n",
            "\n",
            "Epoch 15/25:\n",
            "---------------------\n",
            "train Loss: 0.4176, Acc: 0.8727\n",
            "val Loss: 0.2361, Acc: 0.9386\n",
            "\n",
            "Epoch 16/25:\n",
            "---------------------\n",
            "train Loss: 0.4708, Acc: 0.8356\n",
            "val Loss: 0.1645, Acc: 0.9603\n",
            "\n",
            "Epoch 17/25:\n",
            "---------------------\n",
            "train Loss: 0.4258, Acc: 0.8642\n",
            "val Loss: 0.1698, Acc: 0.9567\n",
            "\n",
            "Epoch 18/25:\n",
            "---------------------\n",
            "train Loss: 0.3577, Acc: 0.8812\n",
            "val Loss: 0.1889, Acc: 0.9603\n",
            "\n",
            "Epoch 19/25:\n",
            "---------------------\n",
            "train Loss: 0.4102, Acc: 0.8812\n",
            "val Loss: 0.2124, Acc: 0.9603\n",
            "\n",
            "Epoch 20/25:\n",
            "---------------------\n",
            "train Loss: 0.4838, Acc: 0.8634\n",
            "val Loss: 0.2059, Acc: 0.9567\n",
            "\n",
            "Epoch 21/25:\n",
            "---------------------\n",
            "train Loss: 0.4649, Acc: 0.8580\n",
            "val Loss: 0.1975, Acc: 0.9603\n",
            "\n",
            "Epoch 22/25:\n",
            "---------------------\n",
            "train Loss: 0.4330, Acc: 0.8627\n",
            "val Loss: 0.1632, Acc: 0.9567\n",
            "\n",
            "Epoch 23/25:\n",
            "---------------------\n",
            "train Loss: 0.4475, Acc: 0.8588\n",
            "val Loss: 0.2205, Acc: 0.9134\n",
            "\n",
            "Epoch 24/25:\n",
            "---------------------\n",
            "train Loss: 0.4119, Acc: 0.8634\n",
            "val Loss: 0.1717, Acc: 0.9458\n",
            "\n",
            "Epoch 25/25:\n",
            "---------------------\n",
            "train Loss: 0.3917, Acc: 0.8688\n",
            "val Loss: 0.2234, Acc: 0.9603\n",
            "\n",
            "Training complete in 1438s Best Validation Acc: 0.9639\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wolnqubjn-fr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "b120d852-a6fe-4cd9-a2ba-a26e06fb5808"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (fc0): Linear(in_features=25088, out_features=2048, bias=True)\n",
              "    (relu1): ReLU()\n",
              "    (dropout1): Dropout(p=0.5, inplace=False)\n",
              "    (fc1): Linear(in_features=2048, out_features=512, bias=True)\n",
              "    (relu2): ReLU()\n",
              "    (dropout2): Dropout(p=0.5, inplace=False)\n",
              "    (fc2): Linear(in_features=512, out_features=102, bias=True)\n",
              "    (output): LogSoftmax(dim=1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBEZ7G1nGqQy"
      },
      "source": [
        "def test(path) :\n",
        "    test_transform = transforms.Compose([\n",
        "                  transforms.Resize(256),\n",
        "                  transforms.CenterCrop(224),\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                ])\n",
        "    img = Image.open(path).convert('RGB')\n",
        "    img_tnsr = test_transform(img).float()\n",
        "    img_tnsr = img_tnsr.unsqueeze_(0)\n",
        "    print(f'predicted class: {class_names[model(img_tnsr.to(device)).data.cpu().numpy().argmax()]}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt1rcK5yHbqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "16e4a02c-f151-406b-86ff-b67d9e2bced7"
      },
      "source": [
        "test('/content/data/test/covid19/covid19-10')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted class: covid19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaefP1llgdhl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea88e358-d762-4178-983a-70df1e6d43ec"
      },
      "source": [
        "test('/content/data/test/covid19/covid19-6')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted class: covid19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYNV6n3Kgdyj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "76747ec3-ae93-4f12-f9ec-149dfa6d98c2"
      },
      "source": [
        "test('/content/data/test/normal/normal11')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted class: normal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETEtDBtKgd-v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8cc0e4ad-627b-43e8-d7b8-8474c7b5d3af"
      },
      "source": [
        "test('/content/data/test/normal/normal6')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted class: normal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL4J10cVgeK4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4794e56-a124-43fc-b3b3-5ff0a17248d1"
      },
      "source": [
        "test('/content/data/test/pneumonia/pneumonia2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted class: pneumonia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXeGy0xJgeZm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "06e8d8b6-8ce4-4238-863d-25313ea8e63f"
      },
      "source": [
        "test('/content/data/test/pneumonia/pneumonia8')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted class: pneumonia\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS6SNxIe45lI"
      },
      "source": [
        "def save_checkpoint(model, optimizer):\n",
        "    \n",
        "    model.to('cpu')\n",
        "\n",
        "    checkpoint = {\n",
        "        'arch': model.arch,\n",
        "        'output_size': model.output_size,\n",
        "        'class_to_idx': model.class_to_idx,\n",
        "        'hidden_layers': model.hidden_layers,\n",
        "        'drop_p': model.drop_p,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }\n",
        "    torch.save(checkpoint, \"/content/data/checkpoint/checkpoint.0.1.pth\")\n",
        "    print('Checkpoint saved')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BukiG1usiawJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58969de7-3582-42c0-a826-772d49106c0e"
      },
      "source": [
        "save_checkpoint( model, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint saved\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}